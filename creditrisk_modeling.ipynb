{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "652bd90a-065a-4d0b-87a1-7fdfb56beb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "AUC: 0.7791533233728691\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.77      0.82     23216\n",
      "           1       0.45      0.63      0.52      6784\n",
      "\n",
      "    accuracy                           0.74     30000\n",
      "   macro avg       0.66      0.70      0.67     30000\n",
      "weighted avg       0.78      0.74      0.75     30000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[17897  5319]\n",
      " [ 2500  4284]]\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's auc: 0.778943\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's auc: 0.779585\n",
      "\n",
      "LightGBM Results:\n",
      "AUC: 0.779585181449155\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89     23216\n",
      "           1       0.76      0.26      0.39      6784\n",
      "\n",
      "    accuracy                           0.81     30000\n",
      "   macro avg       0.79      0.62      0.64     30000\n",
      "weighted avg       0.81      0.81      0.78     30000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[22656   560]\n",
      " [ 4992  1792]]\n",
      "\n",
      "Predicted Probability of Default (Logistic Regression): 0.252\n",
      "Predicted Probability of Default (LightGBM): 0.198\n"
     ]
    }
   ],
   "source": [
    "# Credit Risk Modeling - Python Template\n",
    "# ---------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Load dataset (replace with your file)\n",
    "df = pd.read_csv(\"credit_data.csv\")\n",
    "\n",
    "# -----------------------------\n",
    "# Step 1: Data Preprocessing\n",
    "# -----------------------------\n",
    "# Example cleanup (adapt for your dataset)\n",
    "df = df.dropna(subset=[\"loan_amount\", \"income\"])   # drop rows missing key values\n",
    "df.fillna(0, inplace=True)  # impute other missing values with 0\n",
    "\n",
    "# Encode categoricals\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Step 2: Feature Engineering\n",
    "# -----------------------------\n",
    "if \"credit_limit\" in df.columns and \"current_debt\" in df.columns:\n",
    "    df[\"credit_utilization\"] = df[\"current_debt\"] / (df[\"credit_limit\"] + 1)\n",
    "\n",
    "if \"total_debt\" in df.columns and \"income\" in df.columns:\n",
    "    df[\"debt_to_income\"] = df[\"total_debt\"] / (df[\"income\"] + 1)\n",
    "\n",
    "# Define target and features\n",
    "target = \"default\"   # <-- replace with actual target column (1 = default, 0 = non-default)\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# -----------------------------\n",
    "# Step 3: Logistic Regression\n",
    "# -----------------------------\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "log_reg = LogisticRegression(class_weight=\"balanced\", max_iter=1000)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_lr = log_reg.predict(X_test_scaled)\n",
    "y_prob_lr = log_reg.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"Logistic Regression Results:\")\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_prob_lr))\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lr))\n",
    "\n",
    "# -----------------------------\n",
    "# Step 4: LightGBM\n",
    "# -----------------------------\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \"is_unbalance\": True,  # handles class imbalance\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 31,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"verbose\": -1\n",
    "}\n",
    "\n",
    "lgb_model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    valid_sets=[test_data],\n",
    "    num_boost_round=500,\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(50),     # replaces early_stopping_rounds\n",
    "        lgb.log_evaluation(50)      # replaces verbose_eval\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "y_prob_lgb = lgb_model.predict(X_test, num_iteration=lgb_model.best_iteration)\n",
    "y_pred_lgb = (y_prob_lgb > 0.5).astype(int)\n",
    "\n",
    "print(\"\\nLightGBM Results:\")\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_prob_lgb))\n",
    "print(classification_report(y_test, y_pred_lgb))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lgb))\n",
    "\n",
    "# -----------------------------\n",
    "# Step 5: Predict Probability for New Borrower\n",
    "# -----------------------------\n",
    "# Example new applicant (replace with real values)\n",
    "new_applicant = pd.DataFrame([{\n",
    "    \"loan_amount\": 5000,\n",
    "    \"income\": 45000,\n",
    "    \"current_debt\": 2000,\n",
    "    \"credit_limit\": 10000,\n",
    "    \"total_debt\": 15000,\n",
    "    # include all other features your dataset has!\n",
    "}])\n",
    "\n",
    "# Feature engineering for new applicant\n",
    "new_applicant[\"credit_utilization\"] = new_applicant[\"current_debt\"] / (new_applicant[\"credit_limit\"] + 1)\n",
    "new_applicant[\"debt_to_income\"] = new_applicant[\"total_debt\"] / (new_applicant[\"income\"] + 1)\n",
    "\n",
    "# Align features with training data\n",
    "new_applicant = new_applicant.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "# Logistic Regression probability\n",
    "new_app_scaled = scaler.transform(new_applicant)\n",
    "prob_default_lr = log_reg.predict_proba(new_app_scaled)[:, 1][0]\n",
    "\n",
    "# LightGBM probability\n",
    "prob_default_lgb = lgb_model.predict(new_applicant, num_iteration=lgb_model.best_iteration)[0]\n",
    "\n",
    "print(f\"\\nPredicted Probability of Default (Logistic Regression): {prob_default_lr:.3f}\")\n",
    "print(f\"Predicted Probability of Default (LightGBM): {prob_default_lgb:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95d2ce4-8046-4ba1-9d8f-4d66ffb759da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
